{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":5380830,"sourceType":"datasetVersion","datasetId":3120670}],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport cv2\nimport numpy as np\n\ndef create_dataset(video_dir, label, frame_count=10, frame_size=(256, 256)):\n    videos = []\n    labels = []\n    i=0\n    for video_file in os.listdir(video_dir):\n        video_path = os.path.join(video_dir, video_file)\n        cap = cv2.VideoCapture(video_path)\n        frames = []\n        i+=1\n        print(i, end=\" \")\n        if i == 1000:\n            break\n        # Read the specified number of frames\n        while len(frames) < frame_count:\n            ret, frame = cap.read()\n            if not ret:\n                break\n            # Resize frame\n            frame = cv2.resize(frame, frame_size)\n            frames.append(frame)\n        \n        cap.release()\n        \n        # Only add the video if it has the required number of frames\n        if len(frames) == frame_count:\n            videos.append(np.array(frames))  # Convert frames to NumPy array\n            labels.append(label)\n    \n    return videos, labels  # Return as lists, not as NumPy arrays\n\n# Example usage:\nreal_videos_dir = '/kaggle/input/celeb-df-v2/Celeb-real'\nfake_videos_dir = '/kaggle/input/celeb-df-v2/Celeb-synthesis'\n\n# Create datasets\nreal_videos, real_labels = create_dataset(real_videos_dir, label=1)\nfake_videos, fake_labels = create_dataset(fake_videos_dir, label=0)\n\n# Combine real and fake datasets\nvideos = real_videos + fake_videos\nlabels = real_labels + fake_labels\n\n# Convert lists to NumPy arrays after combining\nvideos = np.array(videos)\nlabels = np.array(labels)\n\nprint(f\"Shape of video dataset: {videos.shape}\")\nprint(f\"Shape of labels: {labels.shape}\")\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-31T11:32:17.392742Z","iopub.execute_input":"2024-08-31T11:32:17.393227Z","iopub.status.idle":"2024-08-31T11:32:42.64755Z","shell.execute_reply.started":"2024-08-31T11:32:17.39315Z","shell.execute_reply":"2024-08-31T11:32:42.646512Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.layers import Input, Conv3D, BatchNormalization, MaxPooling3D, Flatten, Dense, Dropout\nfrom tensorflow.keras.models import Model\n\nclass DeepFakeDetectionModel:\n    def __init__(self, input_shape):\n        self.input_shape = input_shape\n        self.model = self.build_model()\n\n    def build_model(self):\n        inputs = Input(shape=self.input_shape)\n\n        # Convolutional Layer 1\n        x = Conv3D(8, (3, 3, 3), activation='relu', padding='same', name='conv3d_1')(inputs)\n        x = BatchNormalization(name='batch_normalization_1')(x)\n        x = MaxPooling3D((2, 2, 2), name='max_pooling3d_1')(x)\n\n        # Convolutional Layer 2\n        x = Conv3D(16, (3, 3, 3), activation='relu', padding='same', name='conv3d_2')(x)\n        x = BatchNormalization(name='batch_normalization_2')(x)\n        x = MaxPooling3D((2, 2, 2), name='max_pooling3d_2')(x)\n\n        # Convolutional Layer 3\n        x = Conv3D(32, (3, 3, 3), activation='relu', padding='same', name='conv3d_3')(x)\n        x = BatchNormalization(name='batch_normalization_3')(x)\n        x = MaxPooling3D((2, 2, 2), name='max_pooling3d_3')(x)\n\n        # Flatten\n        x = Flatten(name='flatten')(x)\n\n        # Dense Layer\n        x = Dense(64, activation='relu', name='dense_1')(x)\n        x = Dropout(0.5, name='dropout')(x)\n\n        # Output Layer\n        outputs = Dense(1, activation='sigmoid', name='output')(x)\n\n        # Create Model\n        model = Model(inputs=inputs, outputs=outputs, name='DeepFakeDetectionModel')\n\n        # Compile Model\n        model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n\n        return model\n\n    def summary(self):\n        return self.model.summary()\n\n    def train(self, train_data, validation_data, epochs=150, batch_size=16):\n        history = self.model.fit(\n            train_data,\n            validation_data=validation_data,\n            epochs=epochs,\n            batch_size=batch_size\n        )\n        return history\n\n    def evaluate(self, test_data):\n        return self.model.evaluate(test_data)\n\n    def predict(self, data):\n        return self.model.predict(data)\n\n    def save(self, filepath):\n        self.model.save(filepath)\n\n    def load(self, filepath):\n        self.model = tf.keras.models.load_model(filepath)\n\n# Example usage:\n# Define input shape according to your data\nframe_count = 10\nheight = width = 256\nchannels = 3\ninput_shape = (frame_count, height, width, channels)  # (10, 256, 256, 3)\n\n# Initialize the model\ndeepfake_detector = DeepFakeDetectionModel(input_shape)\n\n# Print model summary\ndeepfake_detector.summary()\n\n# Prepare your data\n# Create tf.data.Dataset or use numpy arrays directly\ntrain_data = tf.data.Dataset.from_tensor_slices((videos, labels)).batch(16)\nvalidation_data = tf.data.Dataset.from_tensor_slices((videos, labels)).batch(16)  # Replace with actual validation data\n\n# Train the model\ndeepfake_detector.train(train_data, validation_data, epochs=28)\n\n# Evaluate the model (example)\n# deepfake_detector.evaluate(test_data)\n\n\n\n# Save the model (example)\ndeepfake_detector.save('deepfake_detection_model.h5')\n\n# Load the model (example)\ndeepfake_detector.load('deepfake_detection_model.h5')\n","metadata":{"execution":{"iopub.status.busy":"2024-08-31T11:32:54.797679Z","iopub.execute_input":"2024-08-31T11:32:54.798035Z","iopub.status.idle":"2024-08-31T11:42:03.216756Z","shell.execute_reply.started":"2024-08-31T11:32:54.798003Z","shell.execute_reply":"2024-08-31T11:42:03.21591Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\n\nfile_path = '/kaggle/input/celeb-df-v2/Celeb-synthesis/id17_id30_0004.mp4'\n\n# Check if the file exists\nif os.path.exists(file_path):\n    print(\"File exists.\")\nelse:\n    print(\"File does not exist.\")\n","metadata":{"execution":{"iopub.status.busy":"2024-08-31T11:45:35.30763Z","iopub.execute_input":"2024-08-31T11:45:35.308049Z","iopub.status.idle":"2024-08-31T11:45:35.319685Z","shell.execute_reply.started":"2024-08-31T11:45:35.308013Z","shell.execute_reply":"2024-08-31T11:45:35.318618Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2\nimport numpy as np\n\n# Function to preprocess the frames\ndef preprocess_frame(frame):\n    img = cv2.resize(frame, (256, 256))\n    img = img.astype('float32') / 255.0\n    return img\n\n# Function to detect deepfake in a video\ndef detect_deepfake(video_path, frame_count=10):\n    cap = cv2.VideoCapture(video_path)\n    frames = []\n    deepfake_scores = []\n    i=0\n    while True  :\n        i += 1\n        if i==21 :\n            break\n        ret, frame = cap.read()\n        if not ret:\n            break\n        \n        # Preprocess the frame\n        img = preprocess_frame(frame)\n        \n        # Accumulate frames until we have enough\n        frames.append(img)\n        \n        # If we have enough frames, predict\n        if len(frames) == frame_count:\n            # Convert frames list to a NumPy array with shape (frame_count, height, width, channels)\n            frames_array = np.array(frames)\n            \n            # Predict using the model\n            prediction = deepfake_detector.predict(np.expand_dims(frames_array, axis=0))  # Add batch dimension\n            deepfake_scores.append(prediction[0][0])\n            # Remove the first frame from the list to process the next sequence\n            frames.pop(0)\n\n    cap.release()\n    \n    # Calculate the average score\n    avg_score = np.mean(deepfake_scores) if deepfake_scores else 0\n    print(f\"Average Deepfake Score: {avg_score}\")\n\n    # Determine if the video is deepfake or real\n    if avg_score > 0.5:\n        print(\"The video is likely a Deepfake.\")\n    else:\n        print(\"The video is likely Real.\")\n\n# Example usage\nvideo_path = '/kaggle/input/celeb-df-v2/YouTube-real/00000.mp4'\n# Ensure the model is properly loaded before calling detect_deepfake\n# For example:\n# model = DeepFakeDetectionModel(input_shape=(10, 256, 256, 3)).model\n# model.load_weights('path_to_weights.h5')  # or model.load('path_to_model.h5')\n\n# Detect deepfake\ndetect_deepfake(video_path)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-31T12:45:36.107179Z","iopub.execute_input":"2024-08-31T12:45:36.107845Z","iopub.status.idle":"2024-08-31T12:45:36.977368Z","shell.execute_reply.started":"2024-08-31T12:45:36.107801Z","shell.execute_reply":"2024-08-31T12:45:36.976523Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}